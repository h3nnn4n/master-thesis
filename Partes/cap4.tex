\chapter{Experiments, Results and Analysis}\label{chap:experiments_and_results}

% Present the chapter
In this Chapter the experiment design is presented. Results are shown and an in
depth analysis is conducted, including: Energy and distance metrics for
measuring the performance of the proposed methods; A rigorous statistic testing
of the proposed methods; A comparison to competing methods in the literature in
order to validate the proposed methods; Finally, a visual inspection of the
best predictions and a comparison against the native conformation.
\textcolor{red}{TODO: tem q atualizar aqui conforme for escrevendo}

\section{Design of Experiments}\label{sec:design_of_experiments}

% Present the hardware setup
The experiments were all conducted on a single machine using the same hardware
throughout the full experimentation. Table~\ref{tab:machine-setup}
presents the machine utilized to run all the experiments. Each run of a
prediction method consists of a serial program that run continually without
interruption. The experiments were run in parallel, limited to at most one
running test per core\footnote{Only physical cores were considered. No virtual
(Hyperthreading) core was involved in the computations.}. To ensure maximum
repeatability the machine had no graphical interface enabled or any other form
of user interaction during the course of the experimentation.

\begin{table}[th]
    \centering
    \begin{tabular}{r|l} \hline \hline
        Name & Value \\ \hline \hline
        Operating System & Arch Linux \\ \hline
        Kernel &  Arch Linux Kernel 4.18.16 \\ \hline
        CPU & Intel(R) Core(TM) i5-3570K CPU @ 4.20GHz \\ \hline
        Number of Cores & 4 Physical cores, no hyperthreading cores \\ \hline
        RAM & 16 GB @ 1400 MHz \\ \hline \hline
    \end{tabular}
    \caption{The Machine Setup}
    \label{tab:machine-setup}
\end{table}

The experimentation consisted of running the two proposed methods, namely
SADE-REMC-FINAL and SADE-MC-FINAL. Two of the methods proposed
in~\cite{silva2019self} are also included, Namely SADE-REMC and SADE-MC.
Lastly, the Rosetta Ab Initio protocol is also included, amounting to five
different methods being ran.

The analysis is divided in two steps. In the first one, the two proposed methods
are compared agaisnt the works in~\cite{silva2019self} and the Rosetta Ab Initio
Protocol.
% Present the "in house" comparison
The metrics utilized in this are the \textit{scorefxn} energy value of the
best solution and the \ac{RMSD} associated with the same conformation. The
results were collected over 50 independent runs of each method for each target
protein. A graphical analysis is conducted in order to identify visually the
relative performance between the proposed methods. Considering that a visual
analysis is not enough (in this case), a more rigorous numerical statistic set
of test is conducted.  The Shapiro-Wilk~\cite{wilk1968joint} normality test is
employed with a confidence level of 5\%, i.e. $\alpha = 0.05$, to assess the
presence (or lack) of a underlying normal distribution. Based on its result, a
parametric/non-parametric test is employed with a confidence level of $\alpha =
0.05$. Due to the multiple comparisons involved \v{S}id√°k's $\alpha$ correction
will be utilized~\cite{vsidak1967rectangular}. The winner (or winners)
method(s) will be used in further comparison against the literature. The
processing time for this stage is also analyzed. The time required from the
start of the initial population generation until the final full atom model
output is measured in seconds.
\textcolor{red}{TODO: colocar parameter control analysis}
\textcolor{red}{TODO: convergence analysis}
\textcolor{red}{TODO: ffi analysis}
\textcolor{red}{TODO: mc vs remc analysis}

% Present the "free for all" analysis
In the second analysis step, a direct comparison against several works in the
literature is considered. Since there is a severe lack of standardization in the
literature regarding experimentation, the following methodology was used. Works
that provided the best RMSD had their proteins listed. The proteins that occured
the most were used for comparison. It is worth noting that the majority of works
provide little information about how the experimentation was conducted. The way
in which the results are analysed lacks a standard. As such, this work does a
direct comparison using the best RMSD achieved in a set of runs. While this is
not ideal, due to different works running each method different number of times,
this is possibly the only way to a comparison against several works. The presence
of outliers also weaken this comparison. Also, since only the most used proteins
are select, it is possible that some works are only represented partially, i.e.
some of the results are left out. Nevertheless, at the end of the day for the
PSPP what matters is having the lowest possible error. As such, comparing just
the best RMSD still a worthwhile analysis, albeit not ideal.

% Present the protein set
With that in mind, the set of proteins presented in Table~\ref{tab:protein-targets}
was chosen. The column \textbf{Name} contains the protein identification code
as in PDB.  The \textbf{Size} column shows the number of amino acids in the protein.
The \textbf{Backbone Angles} column shows the number of angles in the backbone,
this also has a one to one relation to the number of variables to be optimized
for a given protein. The \textbf{Structure} column holds the secondary
structures present in the protein set represented by $\alpha$-helices or
$\beta$-sheets.

\begin{table}[bh]
  \centering
  \begin{tabular}{ l | c | c | c | c }
    \hline \hline
    Name & Size & Backbone Angles & Structure         \\ \hline \hline
    1L2Y & 20   & 60              & $2\alpha$         \\ \hline
    1WQC & 26   & 78              & $2\alpha$         \\ \hline
    1ACW & 29   & 87              & $1\alpha, 2\beta$ \\ \hline
    1ZDD & 35   & 105             & $2\alpha$         \\ \hline
    2MR9 & 44   & 132             & $3\alpha$         \\ \hline
    1CRN & 46   & 138             & $2\alpha, 2\beta$ \\ \hline
    1ENH & 54   & 162             & $3\alpha$         \\ \hline
    1ROP & 63   & 189             & $2\alpha$         \\ \hline
    1UTG & 70   & 210             & $4\alpha$         \\ \hline
    1AIL & 72   & 216             & $3\alpha$         \\ \hline
    \hline
  \end{tabular}
  \caption{Target proteins and their features}
  \label{tab:protein-targets}
\end{table}

% present each protein (or maybe not)

% present the two algorithms (MC vs REMC)

% Present the parameters

\begin{table}[ht]
    \centering
    \begin{tabular}{r|l} \hline \hline
        Parameter & Value \\ \hline \hline
        SaDE learning Phase & 50 \\ \hline
        Population Size & 100 \\ \hline
        Function Evaluation Budget & 100000 \\ \hline
        MC/REMC Function Evaluation Budget & 25 \\ \hline \hline
    \end{tabular}
    \caption{Parameters utilized in the proposed methods}
    \label{tab:parameters}
\end{table}

\section{Energy and \ac{RMSD} Analysis}\label{sec:methods-analysis}

% Present the metrics to be utilized

% Show the energy and distance table

% Analyze energy

% Analyze RMSD

% Analyze the avg energy

% Analyze the overall results and conclude

\section{Convergence and Diversity Analysis}
% AVG rmsd plot

\section{Parameter Analysis and Operator Usage}
% Most used parameters over time

\section{Forced Fragment Insertion Analysis}
% What was the impact? How good/bad it was

\section{Repacking Impact}
% How much does the rmsd change before after
% If ranked by energy, does the ranking change before/after repacking

\section{Processing time}

\section{Comparison with Competing Methods}
% Big table here

\input{Tabelas/literature_comparison.tex}

\section{GDT-TS and TM-Score metrics}

\section{Visual Representation of the Predictions}

